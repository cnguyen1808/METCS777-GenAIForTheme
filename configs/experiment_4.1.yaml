## This version works on runpod.io server with 2xL4 GPUs
version: 4.1
model:
  unet:
    pretrained_model_name_or_path: "runwayml/stable-diffusion-v1-5"
    subfolder: "unet"
  vae:
    pretrained_model_name_or_path: "runwayml/stable-diffusion-v1-5"
    subfolder: "vae"
  clip:
    pretrained_model_name_or_path: "openai/clip-vit-large-patch14"
  tokenizer:
    pretrained_model_name_or_path: "openai/clip-vit-large-patch14"
  noise_scheduler:
    name: "DDIMScheduler"
    args:
      num_train_timesteps: 2000
      steps_offset: 1
data:
  path: "./train_set_harvard_met_smithsonian/"
  # Other possible type are imagefolder, csv, ... (which is coming from huggingface load_dataset())
  type: "parquet"
training:
  learning_rate: 0.00001
  batch_size: 16
  epochs: 40
  max_train_steps: 4000
output:
  model: "./output/"
  log: "./log/"
