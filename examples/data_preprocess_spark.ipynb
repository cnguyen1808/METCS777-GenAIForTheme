{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:30:26.471233Z",
     "start_time": "2024-04-23T13:30:10.519445Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/04/23 09:30:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import boto3\n",
    "from datasets import load_dataset\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as F\n",
    "from PIL import Image\n",
    "import io\n",
    "from transformers import CLIPTokenizerFast\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "\n",
    "# Initialize Spark context\n",
    "sc = SparkContext(appName=\"PySpark Image Processing with RDDs\")\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySpark Image Processing with RDDs and DataFrames\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Resolving data files:   0%|          | 0/94 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7968fc8cde944d18c856f0dfb3540ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['image', 'caption'],\n    num_rows: 93\n})"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dataset = load_dataset(\"imagefolder\", data_dir=\"raw_data/harvard/paintings/\", split=\"train\")\n",
    "img_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:30:27.591363Z",
     "start_time": "2024-04-23T13:30:26.473140Z"
    }
   },
   "id": "32b25ab64c03528e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(list(zip(img_dataset['image'], img_dataset['caption'])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:30:29.559915Z",
     "start_time": "2024-04-23T13:30:27.585272Z"
    }
   },
   "id": "c6958b023d64c496"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def resize_and_pad_then_resize(img, final_size=(512, 512), padding_mode='constant', fill=0):\n",
    "    \"\"\"\n",
    "    Resize an image to make its longest side equal to the original image's longest side,\n",
    "    pad the shorter side to make the image a square, then resize to final_size.\n",
    "\n",
    "    Args:\n",
    "        img (PIL.Image): The image to resize and pad.\n",
    "        final_size (tuple): The desired output size (height, width).\n",
    "        padding_mode (str): Type of padding. Options include 'constant', 'edge', etc.\n",
    "        fill (int, tuple): Pixel fill value for constant padding. Can be int or tuple.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The resized and padded, then resized image.\n",
    "    \"\"\"\n",
    "    original_width, original_height = img.size\n",
    "    max_side = max(original_width, original_height)\n",
    "\n",
    "    # Determine new size keeping aspect ratio\n",
    "    if original_width > original_height:\n",
    "        scale = max_side / original_width\n",
    "        new_width = max_side\n",
    "        new_height = int(original_height * scale)\n",
    "    else:\n",
    "        scale = max_side / original_height\n",
    "        new_height = max_side\n",
    "        new_width = int(original_width * scale)\n",
    "\n",
    "    # Resize the image to max_side to keep aspect ratio\n",
    "    img = F.resize(img, (new_height, new_width), interpolation=InterpolationMode.LANCZOS)\n",
    "\n",
    "    # Calculate padding amounts\n",
    "    pad_width = (max_side - new_width) // 2\n",
    "    pad_height = (max_side - new_height) // 2\n",
    "\n",
    "    # Apply padding to make it a square\n",
    "    img = F.pad(img, [pad_width, pad_height, pad_width, pad_height], padding_mode=padding_mode, fill=fill)\n",
    "\n",
    "    # Final resize to the desired output size\n",
    "    img = F.resize(img, final_size, interpolation=InterpolationMode.LANCZOS)\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocess_image(image, caption):\n",
    "    # Setup the transformation pipeline with the updated function\n",
    "    transform_pipeline = T.Compose([\n",
    "        T.Lambda(lambda img: resize_and_pad_then_resize(img, final_size=(512, 512), padding_mode='constant', fill=0)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    processed_image = transform_pipeline(image)\n",
    "\n",
    "    # Tokenization\n",
    "    tokenizer = CLIPTokenizerFast.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
    "    tokens = tokenizer.encode(caption, max_length=77, truncation=True, return_tensors=\"pt\").tolist()[0]\n",
    "\n",
    "    return (processed_image, tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:30:29.577824Z",
     "start_time": "2024-04-23T13:30:29.570570Z"
    }
   },
   "id": "41377d49419f4c0f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "processed_rdd = rdd.map(lambda x: preprocess_image(x[0], x[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:30:29.601867Z",
     "start_time": "2024-04-23T13:30:29.579204Z"
    }
   },
   "id": "d65cfd63e3e1a602"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f137321fe933d87"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/23 09:30:37 WARN TaskSetManager: Stage 0 contains a task of very large size (4964 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           ...,\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n  \n          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           ...,\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n  \n          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           ...,\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]),\n  [49406,\n   4271,\n   3086,\n   281,\n   5727,\n   953,\n   11900,\n   37450,\n   568,\n   257,\n   24717,\n   2889,\n   654,\n   530,\n   518,\n   7374,\n   5603,\n   5873,\n   257,\n   5976,\n   530,\n   34339,\n   14593,\n   267,\n   272,\n   277,\n   275,\n   275,\n   268,\n   272,\n   280,\n   272,\n   272,\n   49407])]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_rdd.take(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:30:45.800666Z",
     "start_time": "2024-04-23T13:30:36.094461Z"
    }
   },
   "id": "c7377267ad4827b6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/23 09:30:50 WARN TaskSetManager: Stage 1 contains a task of very large size (4964 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_set = processed_rdd.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:31:13.776412Z",
     "start_time": "2024-04-23T13:30:50.377245Z"
    }
   },
   "id": "792ee36e50c5a98c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/22 21:28:13 WARN TaskSetManager: Stage 4 contains a task of very large size (4964 KiB). The maximum recommended task size is 1000 KiB.\n",
      "24/04/22 21:28:18 WARN TaskSetManager: Stage 5 contains a task of very large size (6396 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|processed_image|              tokens|\n",
      "+---------------+--------------------+\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "|             {}|[49406, 4271, 308...|\n",
      "+---------------+--------------------+\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T01:28:24.500046Z",
     "start_time": "2024-04-23T01:28:12.740330Z"
    }
   },
   "id": "565ddcf6e4e61957"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/22 20:41:42 WARN TaskSetManager: Stage 0 contains a task of very large size (4964 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": "[(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           ...,\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n  \n          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           ...,\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n  \n          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           ...,\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]),\n  [49406,\n   4271,\n   3086,\n   281,\n   5727,\n   953,\n   11900,\n   37450,\n   568,\n   257,\n   24717,\n   2889,\n   654,\n   530,\n   518,\n   7374,\n   5603,\n   5873,\n   257,\n   5976,\n   530,\n   34339,\n   14593,\n   267,\n   272,\n   277,\n   275,\n   275,\n   268,\n   272,\n   280,\n   272,\n   272,\n   49407])]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_rdd.take(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T00:41:47.735083Z",
     "start_time": "2024-04-23T00:41:41.762640Z"
    }
   },
   "id": "796a5ff307cf4a71"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "formatted_data = {\n",
    "    'pixel_values': [item[0].tolist() for item in train_set],\n",
    "    'input_ids': [item[1] for item in train_set]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(formatted_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:31:29.208391Z",
     "start_time": "2024-04-23T13:31:23.186357Z"
    }
   },
   "id": "16fdca32ac714479"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['pixel_values', 'input_ids'],\n    num_rows: 93\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# DataFrame to Dataset\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-23T13:32:01.670621Z",
     "start_time": "2024-04-23T13:31:58.799071Z"
    }
   },
   "id": "99465e7fd98b56a6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
